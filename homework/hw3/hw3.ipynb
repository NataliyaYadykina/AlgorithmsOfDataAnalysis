{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание <a class=\"anchor\" id=\"hw\"></a><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_u5bV-OlT34p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задача:__ подойдет ли репетитор для подготовки к экзамену по математике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_n6il-AZaLuA"
   },
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявляет функцию standard_scale, которая принимает один аргумент X.\n",
    "# X обычно представляет собой матрицу признаков (набор данных),\n",
    "# где строки — это наблюдения, а столбцы — это признаки (фичи).\n",
    "def standard_scale(X):\n",
    "\n",
    "    # Вычисляется среднее значение для каждого столбца в матрице X.\n",
    "    # Параметр axis=0 указывает на то, что среднее значение вычисляется\n",
    "    # вдоль столбцов (то есть для каждого признака отдельно).\n",
    "    # Результат сохраняется в переменной mean, которая является массивом,\n",
    "    # содержащим средние значения для каждого признака.\n",
    "    mean = X.mean(axis=0)\n",
    "\n",
    "    # Вычисляется стандартное отклонение для каждого столбца в матрице X.\n",
    "    # Параметр axis=0 указывает на то, что\n",
    "    # стандартное отклонение вычисляется вдоль столбцов.\n",
    "    # Результат сохраняется в переменной std, которая является\n",
    "    # массивом стандартных отклонений для каждого признака.\n",
    "    std = X.std(axis=0)\n",
    "\n",
    "    # Выполняет стандартизацию каждого признака в матрице X.\n",
    "    # От каждого элемента столбца вычитается\n",
    "    # соответствующее среднее значение (mean),\n",
    "    # а затем результат делится на соответствующее стандартное отклонение (std).\n",
    "    # Таким образом, каждый признак будет иметь\n",
    "    # среднее значение 0 и стандартное отклонение 1.\n",
    "    # Полученный массив возвращается в качестве результата функции.\n",
    "    return (X - mean) / std\n",
    "\n",
    "# Таким образом, вся функция standard_scale нормализует входную матрицу X,\n",
    "# приводя каждый признак к нулевому среднему значению и единичному стандартному отклонению.\n",
    "# Это часто используется в машинном обучении для улучшения производительности моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.70710678, -0.97958969, -0.89625816],\n",
       "       [ 1.        , -0.70710678, -0.56713087, -0.89625816],\n",
       "       [ 1.        , -0.35355339, -0.46401617,  0.38411064],\n",
       "       [ 1.        ,  0.70710678, -0.77336028, -0.89625816],\n",
       "       [ 1.        ,  0.        ,  0.97958969,  0.38411064],\n",
       "       [ 1.        , -1.06066017, -0.36090146, -0.89625816],\n",
       "       [ 1.        ,  0.70710678,  1.08270439,  1.66447944],\n",
       "       [ 1.        ,  2.47487373,  2.11385144,  1.66447944],\n",
       "       [ 1.        , -0.70710678, -1.08270439, -0.89625816],\n",
       "       [ 1.        , -0.35355339,  0.05155735,  0.38411064]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создает копию матрицы X и преобразует все ее элементы в тип данных float64.\n",
    "# Преобразование в float64 может быть полезным для обеспечения точности вычислений,\n",
    "# особенно если исходные данные имеют другой числовой тип (например, int).\n",
    "# Копия сохраняется в переменной X_st,\n",
    "# чтобы изменения не затрагивали исходную матрицу X.\n",
    "X_st = X.copy().astype(np.float64)\n",
    "\n",
    "# Выполняет стандартизацию подмножества столбцов матрицы X_st,\n",
    "# а именно столбцов с индексами от 1 до 3 включительно\n",
    "# (в Python, как и во многих других языках программирования,\n",
    "#  срезы массивов включают начальный индекс и исключают конечный). \n",
    "# Сначала извлекается подмножество матрицы X_st X_st[:, 1:4],\n",
    "# которое передается в функцию standard_scale для стандартизации.\n",
    "# Результат заменяет исходные значения в тех же столбцах X_st.\n",
    "# - X_st[:, 1:4] выбирает все строки и столбцы с индексами 1, 2 и 3.\n",
    "# - standard_scale(X_st[:, 1:4]) стандартизирует выбранные столбцы,\n",
    "# возвращая новую матрицу, где каждое значение нормализовано.\n",
    "# - X_st[:, 1:4] = ... обновляет эти столбцы\n",
    "# в X_st стандартизированными значениями.\n",
    "X_st[:, 1:4] = standard_scale(X_st[:, 1:4])\n",
    "\n",
    "X_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявляет функцию calc_logloss, которая принимает два аргумента:\n",
    "# - y: массив истинных меток (значений) целевой переменной.\n",
    "# - y_pred: массив предсказанных вероятностей принадлежности к классу 1.\n",
    "def calc_logloss(y, y_pred):\n",
    "\n",
    "    # Заменяет значения y_pred, равные 1, на немного меньшее значение (1 - 1e-8).\n",
    "    # Это необходимо, чтобы избежать логарифма от нуля при вычислении логарифмической функции потерь,\n",
    "    # поскольку log(1 - y_pred) при y_pred = 1 будет равен log(0), что ведет к бесконечности.\n",
    "    # Здесь 1e-8 — это небольшая константа, которая предотвращает эту проблему.\n",
    "    y_pred = np.where(y_pred == 1, 1 - 1e-8, y_pred)\n",
    "\n",
    "    # Аналогично, эта строка заменяет значения y_pred, равные 0,\n",
    "    # на немного большее значение (0 + 1e-8).\n",
    "    # Это делается для избежания вычисления log(0) при вычислении\n",
    "    # логарифмической функции потерь, что также ведет к бесконечности.\n",
    "    y_pred = np.where(y_pred == 0, 0 + 1e-8, y_pred)\n",
    "\n",
    "    # Вычисляет логарифмическую потерю (LogLoss). \n",
    "    # - y * np.log(y_pred) вычисляет вклад положительных примеров в LogLoss.\n",
    "    # - (1.0 - y) * np.log(1.0 - y_pred) вычисляет вклад отрицательных примеров в LogLoss.\n",
    "    # - np.mean(...) вычисляет среднее значение по всем наблюдениям,\n",
    "    # что соответствует делению суммы на количество наблюдений.\n",
    "    # Знак минус - используется, чтобы перевести логарифмическую функцию потерь\n",
    "    # из логарифмов вероятностей в положительную величину,\n",
    "    # так как логарифмы вероятностей дают отрицательные значения.\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "\n",
    "    # Возвращает вычисленное значение логарифмической потери err,\n",
    "    # которое является средним логарифмической потери по всем наблюдениям.\n",
    "    return err\n",
    "\n",
    "# В итоге, функция calc_logloss принимает истинные метки и предсказанные вероятности,\n",
    "# корректирует крайние значения предсказанных вероятностей,\n",
    "# вычисляет логарифмическую потерю и возвращает её."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9999999e-01, 5.0000000e-01, 1.0000000e-08])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определяет небольшую константу eps.\n",
    "# Эта константа будет использоваться для ограничения (clipping) значений,\n",
    "# чтобы избежать проблем с логарифмическими вычислениями (например, логарифма нуля).\n",
    "eps = 1e-8\n",
    "\n",
    "# Использует функцию np.clip для ограничения значений\n",
    "# в массиве [1, 0.5, 0] между eps и 1 - eps.\n",
    "# 1. np.clip — это функция из библиотеки NumPy, которая ограничивает значения в массиве.\n",
    "# Она заменяет значения, выходящие за указанные пределы, на сами эти пределы.\n",
    "# 2. [1, 0.5, 0] — это входной массив, значения которого нужно ограничить.\n",
    "# 3. a_min=eps — это минимальное значение, которое будет использоваться для ограничения.\n",
    "# Любое значение в массиве, меньшее eps, будет заменено на eps.\n",
    "# 4. a_max=1 - eps — это максимальное значение, которое будет использоваться для ограничения.\n",
    "# Любое значение в массиве, большее 1 - eps, будет заменено на 1 - eps.\n",
    "# Функция np.clip применяет эти ограничения ко всем элементам массива.\n",
    "# - Значение 1 больше чем 1 - eps, поэтому оно будет заменено на 1 - eps.\n",
    "# - Значение 0.5 уже находится в пределах от eps до 1 - eps, поэтому оно останется без изменений.\n",
    "# - Значение 0 меньше чем eps, поэтому оно будет заменено на eps.\n",
    "# Результатом выполнения np.clip([1, 0.5, 0], a_min=eps, a_max=1 - eps) будет:\n",
    "# array([1 - 1e-8, 0.5, 1e-8])\n",
    "# Таким образом, конечный результат будет:\n",
    "# array([0.99999999, 0.5, 0.00000001])\n",
    "# Цель этой операции — избежать проблем при вычислении логарифмов вероятностей в таких функциях,\n",
    "# как логарифмическая потеря (LogLoss), где логарифм от 0 или 1\n",
    "# приводит к бесконечности или неопределенным значениям.\n",
    "np.clip([1, 0.5, 0], a_min=eps, a_max=1 - eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявляет функцию calc_logloss, которая принимает два аргумента:\n",
    "# - y: массив истинных меток (значений) целевой переменной.\n",
    "# - y_pred: массив предсказанных вероятностей принадлежности к классу 1.\n",
    "def calc_logloss(y, y_pred):\n",
    "\n",
    "    # Определяет небольшую константу eps.\n",
    "    # Эта константа будет использоваться для ограничения значений предсказанных вероятностей,\n",
    "    # чтобы избежать логарифма нуля и бесконечных значений при вычислении логарифмов.\n",
    "    eps = 1e-8\n",
    "\n",
    "    # Использует функцию np.clip из библиотеки NumPy для ограничения\n",
    "    # значений массива y_pred между eps и 1 - eps.\n",
    "    # Функция np.clip заменяет значения в массиве,\n",
    "    # выходящие за указанные пределы, на сами эти пределы:\n",
    "    # - Любое значение в y_pred, меньшее eps, будет заменено на eps.\n",
    "    # - Любое значение в y_pred, большее 1 - eps, будет заменено на 1 - eps.\n",
    "    # Это необходимо, чтобы избежать вычислений вида log(0) и log(1) в следующих строках,\n",
    "    # которые приводят к неопределенным значениям или бесконечности.\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "    # Вычисляет логарифмическую потерю (LogLoss).\n",
    "    # - y * np.log(y_pred) вычисляет вклад положительных примеров в LogLoss.\n",
    "    # - (1.0 - y) * np.log(1.0 - y_pred) вычисляет вклад отрицательных примеров в LogLoss.\n",
    "    # - np.mean(...) вычисляет среднее значение по всем наблюдениям,\n",
    "    # что соответствует делению суммы на количество наблюдений.\n",
    "    # Знак минус - используется для перевода логарифмической функции потерь\n",
    "    # из логарифмов вероятностей в положительную величину,\n",
    "    # так как логарифмы вероятностей дают отрицательные значения.\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "\n",
    "    # Возвращает вычисленное значение логарифмической потери err,\n",
    "    # которое является средним логарифмической потери по всем наблюдениям.\n",
    "    return err\n",
    "\n",
    "# В итоге, функция calc_logloss принимает истинные метки и предсказанные вероятности,\n",
    "# ограничивает предсказанные вероятности в диапазоне от eps до 1 - eps,\n",
    "# вычисляет логарифмическую потерю и возвращает её."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код реализует функцию для вычисления логарифмической потери (LogLoss)\n",
    "# без использования библиотечных функций, таких как np.clip или np.mean. \n",
    "\n",
    "# Определяет функцию calc_logloss, которая принимает два аргумента:\n",
    "# - y: массив истинных меток (значений) целевой переменной.\n",
    "# - y_pred: массив предсказанных вероятностей принадлежности к классу 1.\n",
    "def calc_logloss(y, y_pred):\n",
    "\n",
    "    # Инициализирует переменную err с нулевым значением.\n",
    "    # В этой переменной будет накапливаться суммарная потеря для всех наблюдений.\n",
    "    err = 0\n",
    "\n",
    "    # Начинает цикл, который будет выполнен для каждого индекса i в диапазоне длины массива y.\n",
    "    # Это позволяет перебирать каждую пару истинной метки и предсказанной вероятности.\n",
    "    for i in range(len(y)):\n",
    "\n",
    "        # Если предсказанная вероятность y_pred[i] равна нулю,\n",
    "        # то мы используем формулу для логарифмической потери для случая,\n",
    "        # когда истинное значение y[i] равно 1.\n",
    "        # В этом случае потеря будет равна (1 - y[i]) * log(1 - y_pred[i]).\n",
    "        # Заметим, что мы используем значение 1.0 - y_pred[i],\n",
    "        # чтобы избежать вычисления логарифма отрицательного числа.\n",
    "        if y_pred[i] == 0:\n",
    "            err += (1.0 - y[i]) * np.log(1.0 - y_pred[i])\n",
    "\n",
    "        # Если предсказанная вероятность y_pred[i] равна единице,\n",
    "        # то мы используем формулу для логарифмической потери для случая,\n",
    "        # когда истинное значение y[i] равно 1.\n",
    "        # В этом случае потеря будет равна y[i] * log(y_pred[i]).\n",
    "        elif y_pred[i] == 1:\n",
    "            err += y[i] * np.log(y_pred[i])\n",
    "\n",
    "        # В остальных случаях (когда предсказанная вероятность не равна ни нулю, ни единице),\n",
    "        # мы используем полную формулу для логарифмической потери.\n",
    "        # Она включает два слагаемых: одно для случая, когда истинное значение y[i] равно 1,\n",
    "        # и второе для случая, когда y[i] равно 0.\n",
    "        else:\n",
    "            err += y[i] * np.log(y_pred[i]) + (1.0 - y[i]) * np.log(1.0 - y_pred[i])\n",
    "\n",
    "    # Возвращает усредненное значение потери, деленное на количество наблюдений и знак минус,\n",
    "    # чтобы вернуть результат в соответствии с общепринятым определением LogLoss. \n",
    "    return - err / len(y)\n",
    "\n",
    "# Таким образом, функция calc_logloss вычисляет логарифмическую потерю,\n",
    "# проходя по каждому наблюдению и используя соответствующую формулу\n",
    "# в зависимости от предсказанной вероятности и истинного значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05268025782891314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Код использует ранее определенную функцию calc_logloss\n",
    "# для вычисления логарифмической потери (LogLoss)\n",
    "# для заданных истинных меток y1 и предсказанных вероятностей y_pred1.\n",
    "\n",
    "# Создает массив y1, который содержит истинные метки для двух наблюдений.\n",
    "# В данном случае первое наблюдение имеет метку 1 (принадлежит классу 1),\n",
    "# а второе наблюдение имеет метку 0 (принадлежит классу 0).\n",
    "y1 = np.array([1, 0])\n",
    "\n",
    "# Создает массив y_pred1, который содержит предсказанные вероятности\n",
    "# принадлежности к классу 1 для двух наблюдений.\n",
    "# В данном случае первое наблюдение имеет предсказанную вероятность 0.9,\n",
    "# а второе наблюдение имеет предсказанную вероятность 0.\n",
    "y_pred1 = np.array([0.9, 0])\n",
    "\n",
    "# Вызывает ранее определенную функцию calc_logloss и передает ей\n",
    "# истинные метки y1 и предсказанные вероятности y_pred1.\n",
    "# Функция calc_logloss вычислит логарифмическую потерю для этих данных.\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05268025782891314"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([1, 0.1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10536051565782628"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([0.9, 0.1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код определяет функцию сигмоиды, которая используется в логистической регрессии\n",
    "# для преобразования линейной комбинации весов\n",
    "# и признаков в вероятность принадлежности к классу 1.\n",
    "\n",
    "# Определяет функцию sigmoid с одним аргументом z,\n",
    "# который представляет собой линейную комбинацию весов и признаков.\n",
    "def sigmoid(z):\n",
    "\n",
    "    # Вычисляет сигмоиду от аргумента z.\n",
    "    # np.exp(-z) вычисляет экспоненту от отрицания z,\n",
    "    # а 1 / (1 + ...) вычисляет сигмоиду по формуле.\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    # Возвращает результат вычисления сигмоиды.\n",
    "    # Результат представляет собой вероятность принадлежности\n",
    "    # к классу 1 для данного наблюдения, представленную в диапазоне от 0 до 1.\n",
    "    return res\n",
    "\n",
    "# Итак, функция sigmoid принимает в качестве входных данных\n",
    "# линейную комбинацию весов и признаков\n",
    "# и возвращает вероятность принадлежности к классу 1 для данного наблюдения,\n",
    "# преобразованную с использованием сигмоидной функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код реализует процесс обучения модели логистической регрессии с использованием градиентного спуска.\n",
    "\n",
    "# Определяет функцию eval_model, которая принимает четыре аргумента:\n",
    "# - X: матрица признаков.\n",
    "# - y: вектор истинных меток классов.\n",
    "# - iterations: количество итераций обучения.\n",
    "# - eta: скорость обучения (по умолчанию 1e-4).\n",
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "\n",
    "    # Устанавливает начальное значение генератора\n",
    "    # случайных чисел для воспроизводимости результатов.\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Инициализирует веса модели случайными значениями\n",
    "    # из стандартного нормального распределения.\n",
    "    # Размерность вектора весов соответствует количеству признаков в матрице X.\n",
    "    W = np.random.randn(X.shape[1])\n",
    "\n",
    "    # Вычисляет количество наблюдений в матрице признаков X.\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Начинает цикл, который будет повторен iterations раз\n",
    "    # для обновления параметров модели.\n",
    "    for i in range(iterations):\n",
    "\n",
    "        # Вычисляют прогнозы модели, значение функции потерь (LogLoss)\n",
    "        # и ошибку для текущих весов модели.\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        # Вычисляет градиент функции потерь по параметрам модели.\n",
    "        # Градиент выражается как среднее значение градиентов для всех наблюдений.\n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "\n",
    "        # Обновляет веса модели в направлении, противоположном градиенту,\n",
    "        # с учетом скорости обучения eta.\n",
    "        W -= eta * dQ\n",
    "\n",
    "        # Выводит текущее значение итерации, веса модели и значение функции потерь\n",
    "        # каждые 10% от общего количества итераций.\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    \n",
    "    # Вычисляют и возвращают значение функции потерь\n",
    "    # для финальных предсказаний и веса модели после завершения всех итераций.\n",
    "    final_error = calc_logloss(y, y_pred)\n",
    "    return W, final_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 метод\n",
    "\n",
    "аналог GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m), np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Этот код использует функции np.logspace и np.linspace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# из библиотеки NumPy для создания массивов чисел с различными интервалами.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# В обоих случаях np.logspace и np.linspace создают массивы значений\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# с различными интервалами для использования в различных вычислениях или визуализациях.\u001b[39;00m\n",
      "File \u001b[1;32me:\\DS_GB\\AlgorithmsOfDataAnalysis\\.venv\\Lib\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "np.logspace(2, 4, 4, dtype=np.int), np.linspace(1e-2, 5, 10)\n",
    "\n",
    "# Этот код использует функции np.logspace и np.linspace\n",
    "# из библиотеки NumPy для создания массивов чисел с различными интервалами.\n",
    "\n",
    "# np.logspace(2, 4, 4, dtype=np.int)\n",
    "# Эта строка создает массив чисел, равномерно распределенных\n",
    "# в логарифмической шкале от \\(10^2\\) до \\(10^4\\).\n",
    "# В качестве аргументов передаются:\n",
    "# - 2: начальное значение логарифма.\n",
    "# - 4: конечное значение логарифма.\n",
    "# - 4: количество чисел в массиве.\n",
    "# - dtype=np.int: тип данных элементов массива, в данном случае целые числа.\n",
    "# Таким образом, массив будет содержать четыре целых числа,\n",
    "# равномерно распределенных в логарифмической шкале от 100 до 10000.\n",
    "\n",
    "# np.linspace(1e-2, 5, 10)\n",
    "# Эта строка создает массив чисел, равномерно распределенных в линейной шкале от \\(10^{-2}\\) до 5. В качестве аргументов передаются:\n",
    "# - 1e-2: начальное значение.\n",
    "# - 5: конечное значение.\n",
    "# - 10: количество чисел в массиве.\n",
    "# Таким образом, массив будет содержать десять чисел,\n",
    "# равномерно распределенных в линейной шкале от 0.01 до 5. \n",
    "\n",
    "# В обоих случаях np.logspace и np.linspace создают массивы значений\n",
    "# с различными интервалами для использования в различных вычислениях или визуализациях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Создает массив iterations, содержащий четыре значения,\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# равномерно распределенные в логарифмической шкале от \\(10^2\\) до \\(10^4\\).\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Тип данных указан как целочисленный (dtype=np.int).\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m iterations \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Создает массив etas, содержащий десять значений,\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# равномерно распределенных в линейной шкале от \\(10^{-2}\\) до 5.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m etas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32me:\\DS_GB\\AlgorithmsOfDataAnalysis\\.venv\\Lib\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# Создает массив iterations, содержащий четыре значения,\n",
    "# равномерно распределенные в логарифмической шкале от \\(10^2\\) до \\(10^4\\).\n",
    "# Тип данных указан как целочисленный (dtype=np.int).\n",
    "iterations = np.logspace(2, 4, 4, dtype=np.int)\n",
    "\n",
    "# Создает массив etas, содержащий десять значений,\n",
    "# равномерно распределенных в линейной шкале от \\(10^{-2}\\) до 5.\n",
    "etas = np.linspace(1e-2, 5, 10)\n",
    "\n",
    "# Инициализируют переменные best_error и best_params.\n",
    "# best_error устанавливается в бесконечность (np.inf), а best_params в пустой словарь.\n",
    "# Они будут использоваться для хранения лучшего значения ошибки\n",
    "# и соответствующих параметров обучения.\n",
    "best_error = np.inf\n",
    "best_params = {}\n",
    "\n",
    "# Запускают вложенный цикл для перебора всех комбинаций значений iterations и etas.\n",
    "# Для каждой комбинации запускается обучение модели с использованием функции eval_model.\n",
    "# Если текущее значение ошибки меньше best_error,\n",
    "# то best_error обновляется на текущее значение ошибки,\n",
    "# а best_params устанавливается в текущие параметры обучения (iteration и eta).\n",
    "for iteration in tqdm(iterations):\n",
    "    for eta in etas:\n",
    "        W, error = eval_model(X_st, y, iterations=iteration, eta=eta)\n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_params = {\n",
    "                'iteration': iteration,\n",
    "                'eta': eta\n",
    "            }\n",
    "\n",
    "# Выводит информацию о лучшем значении ошибки и соответствующих параметрах обучения.\n",
    "print(f'Ошибка {best_error} при параметрах {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 метод\n",
    "\n",
    "Вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.46121499 -0.40908382  0.41426183  1.39855008] 0.760958797591889\n",
      "10 [ 0.0387634  -1.30386446 -0.15001914  1.74758184] 0.4254600283700163\n",
      "20 [-0.01161527 -1.64023671 -0.31196552  2.27533881] 0.38108858271134755\n",
      "30 [-0.01156172 -1.88360488 -0.46035705  2.69723081] 0.35422352980840865\n",
      "40 [ 9.33444488e-04 -2.07189803e+00 -5.97280973e-01  3.05064764e+00] 0.3358002141655348\n",
      "50 [ 0.01934395 -2.22448855 -0.72422385  3.35653644] 0.32217454105883114\n",
      "60 [ 0.04127542 -2.35245169 -0.84255667  3.6277315 ] 0.3115442516500474\n",
      "70 [ 0.06539266 -2.46266676 -0.95347146  3.87262358] 0.30291439965765515\n",
      "80 [ 0.090846   -2.55967079 -1.05796576  4.09697143] 0.29569092767181626\n",
      "90 [ 0.11707191 -2.64659092 -1.15686395  4.30488038] 0.28949721467181433\n"
     ]
    }
   ],
   "source": [
    "W, error = eval_model(X_st, y, iterations=100, eta=1)\n",
    "# 1. `eval_model: Это функция, которая выполняет обучение модели\n",
    "# логистической регрессии с помощью градиентного спуска.\n",
    "# 2. X_st: Это матрица признаков, которая представляет собой набор данных,\n",
    "# подготовленных для обучения модели. Обычно она предварительно масштабирована\n",
    "# с помощью стандартизации или нормализации.\n",
    "# 3. y: Это вектор истинных меток классов, соответствующих данным в X_st.\n",
    "# 4. iterations=100: Это количество итераций обучения модели.\n",
    "# В данном случае модель будет обучаться в течение 100 итераций.\n",
    "# 5. eta=1: Это скорость обучения (learning rate),\n",
    "# которая определяет шаг градиентного спуска.\n",
    "# Значение 1 указывает на то, что на каждой итерации веса модели\n",
    "# будут обновляться на величину, пропорциональную градиенту функции потерь.\n",
    "# 6. W: Это вектор весов модели после обучения.\n",
    "# 7. error`: Это значение функции потерь (в данном случае, LogLoss) на последней итерации обучения.\n",
    "# Таким образом, данная строка кода запускает процесс обучения модели логистической регрессии\n",
    "# с фиксированными параметрами: 100 итераций обучения и скорость обучения, равную 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяет функцию с именем calc_pred_proba, которая принимает два аргумента:\n",
    "#    - W: это вектор весов модели логистической регрессии.\n",
    "#    - X: это матрица признаков, для которой мы хотим вычислить предсказанные вероятности.\n",
    "def calc_pred_proba(W, X):\n",
    "\n",
    "    # Вычисляет предсказанные вероятности принадлежности к классу 1\n",
    "    # для каждого наблюдения в матрице `X`.\n",
    "    # Для этого сначала выполняется линейная комбинация весов модели и признаков\n",
    "    # (произведение матриц `X` и `W` с помощью `np.dot`),\n",
    "    # а затем результат подается на вход функции `sigmoid`,\n",
    "    # чтобы преобразовать его в вероятность.\n",
    "    y_pred_proba = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # возвращает вычисленные предсказанные вероятности принадлежности к классу 1. \n",
    "    return y_pred_proba\n",
    "\n",
    "# Итак, функция `calc_pred_proba` принимает на вход\n",
    "# вектор весов модели `W` и матрицу признаков `X`,\n",
    "# а затем возвращает предсказанные вероятности\n",
    "# принадлежности каждого наблюдения к классу 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32380055, 0.22296142, 0.96767742, 0.00787362, 0.65604029,\n",
       "       0.36735518, 0.98703363, 0.14768606, 0.35244079, 0.94041789])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Код вычисляет предсказанные вероятности принадлежности к классу 1\n",
    "# для набора данных X_st с использованием весов модели W.\n",
    "calc_pred_proba(W, X_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяет функцию с именем calc_pred, которая принимает два аргумента:\n",
    "#    - W: это вектор весов модели логистической регрессии.\n",
    "#    - X: это матрица признаков, для которой мы хотим сделать предсказания.\n",
    "def calc_pred(W, X):\n",
    "\n",
    "    # Вызывает ранее определенную функцию `calc_pred_proba`\n",
    "    # для вычисления предсказанных вероятностей принадлежности к классу 1\n",
    "    # для каждого наблюдения в матрице `X`.\n",
    "    # Результат сохраняется в переменной `y_pred_proba`.\n",
    "    y_pred_proba = calc_pred_proba(W, X)\n",
    "\n",
    "    # Создает вектор предсказанных меток классов на основе предсказанных вероятностей.\n",
    "    # Если вероятность принадлежности к классу 1 больше 0.5,\n",
    "    # то соответствующая метка класса будет 1, иначе - 0.\n",
    "    # Функция `np.where` выполняет это условие\n",
    "    # для каждого элемента вектора `y_pred_proba`.\n",
    "    y_pred = np.where(y_pred_proba > 0.5, 1, 0)\n",
    "\n",
    "    # Возвращает вектор предсказанных меток классов.\n",
    "    return y_pred\n",
    "\n",
    "# Итак, функция `calc_pred` принимает на вход вектор весов модели `W` и матрицу признаков `X`,\n",
    "# вычисляет предсказанные вероятности принадлежности к классу 1 для каждого наблюдения\n",
    "# и на их основе делает предсказания меток классов, которые затем возвращает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вызывает функцию calc_pred с двумя аргументами:\n",
    "#    - W: это вектор весов модели логистической регрессии.\n",
    "#    - X_st: это матрица признаков, для которой мы хотим сделать предсказания.\n",
    "pred = calc_pred(W, X_st)\n",
    "\n",
    "# Эта переменная будет содержать предсказанные метки классов,\n",
    "# которые возвращаются из функции calc_pred.\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. *Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяет функцию с именем accuracy, которая принимает два аргумента:\n",
    "#    - y: вектор истинных меток классов.\n",
    "#    - y_pred: вектор предсказанных меток классов.\n",
    "def accuracy(y, y_pred):\n",
    "\n",
    "    # Вычисляет точность предсказаний, сравнивая вектор истинных меток `y`\n",
    "    # с вектором предсказанных меток `y_pred`.\n",
    "    # Она возвращает долю правильно предсказанных меток, то есть долю элементов вектора `y`,\n",
    "    # которые равны соответствующим элементам вектора `y_pred`.\n",
    "    # Функция `np.mean` вычисляет среднее значение булевого вектора,\n",
    "    # преобразуя `True` в 1 и `False` в 0.\n",
    "    accuracy = np.mean(y == y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Итак, функция `accuracy` принимает на вход два вектора меток классов -\n",
    "# истинных `y` и предсказанных `y_pred`,\n",
    "# и возвращает долю правильно предсказанных меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \t  [0 0 1 0 1 0 1 0 1 1]\n",
      "Predicted [0 0 1 0 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(f'True \\t  {y}')\n",
    "print(f'Predicted {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Confusion Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP  FP\n",
    "# FN  TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяет функцию с именем confusion_matrix, которая принимает два аргумента:\n",
    "#    - y: вектор истинных меток классов.\n",
    "#    - y_pred: вектор предсказанных меток классов.\n",
    "def confusion_matrix(y, y_pred):\n",
    "\n",
    "    # Создает нулевую матрицу размером 2x2,\n",
    "    # которая будет представлять собой матрицу ошибок (confusion matrix)\n",
    "    # для двух классов: класс 1 и класс 0.\n",
    "    cm = np.zeros((2, 2))\n",
    "\n",
    "    # Начинает цикл по всем элементам вектора истинных меток `y`.\n",
    "    for i in range(len(y)): \n",
    "\n",
    "        # Если текущий элемент вектора истинных меток `y`\n",
    "        # и вектора предсказанных меток `y_pred` равен 1 (означает истинно положительный случай),\n",
    "        # то это увеличивает количество истинно положительных (True Positive) случаев в матрице ошибок на 1.\n",
    "        if y[i] == y_pred[i] == 1: # TP\n",
    "            cm[0][0] += 1\n",
    "\n",
    "        # Если текущий элемент вектора истинных меток `y`\n",
    "        # и вектора предсказанных меток `y_pred` равен 0 (означает истинно отрицательный случай),\n",
    "        # то это увеличивает количество истинно отрицательных (True Negative) случаев в матрице ошибок на 1.\n",
    "        elif y[i] == y_pred[i] == 0: # TN\n",
    "            cm[1][1] += 1\n",
    "\n",
    "        # Если истинная метка класса равна 1, а предсказанная метка класса не равна 1\n",
    "        # (означает ложно отрицательный случай),\n",
    "        # то это увеличивает количество ложно отрицательных (False Negative) случаев в матрице ошибок на 1.\n",
    "        elif y[i] != y_pred[i] and y[i] == 1: # FN\n",
    "            cm[1][0] += 1\n",
    "\n",
    "        # Если истинная метка класса равна 0, а предсказанная метка класса не равна 0\n",
    "        # (означает ложно положительный случай),\n",
    "        # то это увеличивает количество ложно положительных (False Positive) случаев в матрице ошибок на 1.\n",
    "        elif y[i] != y_pred[i] and y[i] == 0: # FP\n",
    "            cm[0][1] += 1\n",
    "\n",
    "    # Возвращает заполненную матрицу ошибок.\n",
    "    return cm\n",
    "\n",
    "# Итак, функция `confusion_matrix` принимает на вход вектор истинных меток классов `y`\n",
    "# и вектор предсказанных меток классов `y_pred`, вычисляет и возвращает матрицу ошибок,\n",
    "# которая содержит информацию о количестве верно и ошибочно классифицированных наблюдений для каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 0.],\n",
       "       [1., 5.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Precision*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяет функцию с именем precision, которая принимает два аргумента:\n",
    "#    - y: вектор истинных меток классов.\n",
    "#    - y_pred: вектор предсказанных меток классов.\n",
    "def precision(y, y_pred):\n",
    "\n",
    "    # Вызывает функцию `confusion_matrix` для вычисления матрицы ошибок\n",
    "    # на основе векторов истинных и предсказанных меток классов.\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "    # Эти строки извлекают из матрицы ошибок количество\n",
    "    # истинно положительных (`TP`), истинно отрицательных (`TN`),\n",
    "    # ложно положительных (`FP`) и ложно отрицательных (`FN`)\n",
    "    # случаев соответственно.\n",
    "    TP = cm[0][0]\n",
    "    TN = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "\n",
    "    # Вычисляет точность (precision) модели как отношение\n",
    "    # истинно положительных случаев к сумме\n",
    "    # истинно положительных и ложно положительных случаев.\n",
    "    # Точность характеризует способность модели\n",
    "    # классифицировать объекты положительного класса корректно.\n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    # Возвращает вычисленное значение точности.\n",
    "    return precision\n",
    "\n",
    "# Итак, функция `precision` принимает на вход векторы истинных\n",
    "# и предсказанных меток классов, вычисляет и возвращает точность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recall*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяет функцию с именем recall, которая принимает два аргумента:\n",
    "#    - y: вектор истинных меток классов.\n",
    "#    - y_pred: вектор предсказанных меток классов.\n",
    "def recall(y, y_pred):\n",
    "\n",
    "    # Вызывает функцию `confusion_matrix` для вычисления матрицы ошибок\n",
    "    # на основе векторов истинных и предсказанных меток классов.\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "    # Эти строки извлекают из матрицы ошибок количество\n",
    "    # истинно положительных (`TP`), истинно отрицательных (`TN`),\n",
    "    # ложно положительных (`FP`) и ложно отрицательных (`FN`)\n",
    "    # случаев соответственно.\n",
    "    TP = cm[0][0]\n",
    "    TN = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "\n",
    "    # Вычисляет полноту (recall) модели как отношение истинно положительных случаев\n",
    "    # к сумме истинно положительных и ложно отрицательных случаев.\n",
    "    # Полнота характеризует способность модели обнаруживать\n",
    "    # все объекты положительного класса.\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    # Возвращает вычисленное значение полноты.\n",
    "    return recall\n",
    "\n",
    "# Итак, функция `recall` принимает на вход векторы истинных\n",
    "# и предсказанных меток классов, вычисляет и возвращает полноту модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*F-score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяет функцию с именем f_score, которая принимает два аргумента:\n",
    "#    - y: вектор истинных меток классов.\n",
    "#    - y_pred: вектор предсказанных меток классов.\n",
    "def f_score(y, y_pred):\n",
    "\n",
    "    # Вызывает функцию `precision` для вычисления точности модели.\n",
    "    pr = precision(y, y_pred)\n",
    "\n",
    "    # Вызывает функцию `recall` для вычисления полноты модели.\n",
    "    rec = recall(y, y_pred)\n",
    "\n",
    "    # Вычисляет F-меру (F-score) модели, которая является\n",
    "    # гармоническим средним между точностью (`pr`) и полнотой (`rec`).\n",
    "    # Она определяется как \\(F = \\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}\\).\n",
    "    # F-мера объединяет точность и полноту в единую метрику,\n",
    "    # учитывая как правильность классификации положительных классов,\n",
    "    # так и способность модели обнаруживать все объекты положительного класса.\n",
    "    f_score = 2 * pr * rec / (pr + rec)\n",
    "\n",
    "    # Возвращает вычисленное значение F-меры.\n",
    "    return f_score\n",
    "\n",
    "# Итак, функция `f_score` принимает на вход векторы истинных\n",
    "# и предсказанных меток классов, вычисляет и возвращает F-меру модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F-score определяется как \\(F = $\\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888888888888889"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9\n",
      "precision 1.0\n",
      "recall 0.8\n",
      "f-score 0.8888888888888888\n",
      "\n",
      " [[5 0]\n",
      " [1 4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Выводит значение точности модели, которая вычисляется\n",
    "# с помощью функции `accuracy_score` из библиотеки `scikit-learn`.\n",
    "# Эта функция сравнивает векторы истинных меток `y`\n",
    "# с предсказанными метками `pred` и вычисляет долю правильных предсказаний.\n",
    "print(f'accuracy {accuracy_score(y, pred)}')\n",
    "\n",
    "# Выводит значение точности модели, которая вычисляется\n",
    "# с помощью функции `precision_score` из библиотеки `scikit-learn`.\n",
    "# Эта функция вычисляет точность модели, которая характеризует\n",
    "# способность модели классифицировать объекты положительного класса корректно.\n",
    "print(f'precision {precision_score(y, pred)}')\n",
    "\n",
    "# Выводит значение полноты модели, которая вычисляется\n",
    "# с помощью функции `recall_score` из библиотеки `scikit-learn`.\n",
    "# Эта функция вычисляет полноту модели, которая характеризует\n",
    "# способность модели обнаруживать все объекты положительного класса.\n",
    "print(f'recall {recall_score(y, pred)}')\n",
    "\n",
    "# Выводит значение F-меры модели, которая вычисляется\n",
    "# с помощью функции `f1_score` из библиотеки `scikit-learn`.\n",
    "# F-мера является гармоническим средним между точностью и полнотой,\n",
    "# и она характеризует сбалансированность модели между\n",
    "# обнаружением объектов положительного класса и избежанием ложных срабатываний.\n",
    "print(f'f-score {f1_score(y, pred)}')\n",
    "\n",
    "# Выводит матрицу ошибок (confusion matrix), которая представляет собой\n",
    "# таблицу, показывающую количество верно и ошибочно классифицированных наблюдений для каждого класса.\n",
    "# Она вычисляется с помощью функции `confusion_matrix` из библиотеки `scikit-learn`.\n",
    "print(f'\\n {confusion_matrix(y, pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
