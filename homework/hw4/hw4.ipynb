{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание <a class=\"anchor\" id=\"hw\"></a><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "# Объявление класса Node. В дереве решений каждый узел\n",
    "# представляет собой объект этого класса.\n",
    "class Node:\n",
    "    \n",
    "    # Метод инициализации initit__, который вызывается при создании нового объекта класса Node.\n",
    "    # Он принимает следующие параметры:\n",
    "    # - index: индекс признака (колонки), по которому ведется сравнение с порогом.\n",
    "    # - t: значение порога, с которым сравнивается значение признака.\n",
    "    # - true_branch: поддерево, к которому переходят,\n",
    "    # если условие (значение признака > порог) выполняется.\n",
    "    # - false_branch: поддерево, к которому переходят, если условие не выполняется.\n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index\n",
    "        self.t = t\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "    # В итоге, класс Node определяет структуру узла дерева решений,\n",
    "    # где каждый узел содержит информацию о том, по какому признаку\n",
    "    # и с каким порогом проводится разделение,\n",
    "    # а также ссылки на два поддерева — одно для случаев,\n",
    "    # когда условие выполняется, и другое для случаев,\n",
    "    # когда оно не выполняется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет прироста\n",
    "\n",
    "# Определение функции gain, которая принимает четыре параметра:\n",
    "# - left_labels: метки классов в левом поддереве.\n",
    "# - right_labels: метки классов в правом поддереве.\n",
    "# - root_criterion: значение критерия на текущем (исходном) узле до разделения.\n",
    "# - criterion: функция, вычисляющая значение критерия\n",
    "# (например, Gini, энтропия) для набора меток классов.\n",
    "def gain(left_labels, right_labels, root_criterion, criterion):\n",
    "\n",
    "    # Вычисляет долю выборки, которая ушла в левое поддерево.\n",
    "    # Для этого берется количество элементов в левом поддереве (left_labels.shape[0])\n",
    "    # и делится на общее количество элементов (сумма элементов в левом и правом поддеревьях).\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    # Возвращает значение прироста (gain). Формула для вычисления прироста:\n",
    "    # - root_criterion: значение критерия на текущем узле до разделения.\n",
    "    # - p * criterion(left_labels): взвешенное значение критерия для левого поддерева.\n",
    "    # - (1 - p) * criterion(right_labels): взвешенное значение критерия для правого поддерева.\n",
    "    # Итоговый прирост получается вычитанием взвешенных значений критерия\n",
    "    # для поддеревьев из значения критерия на текущем узле.\n",
    "    return root_criterion - p * criterion(left_labels) - (1 - p) * criterion(right_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение датасета в узле\n",
    "\n",
    "# Определение функции split, которая принимает четыре параметра:\n",
    "# - data: матрица данных, где каждая строка — это объект, а каждый столбец — это признак.\n",
    "# - labels: вектор меток классов для объектов.\n",
    "# - column_index: индекс признака, по которому выполняется разбиение.\n",
    "# - t: пороговое значение для разбиения.\n",
    "def split(data, labels, column_index, t):\n",
    "    \n",
    "    # Создают два массива индексов:\n",
    "    # - left: индексы объектов, у которых значение признака\n",
    "    # в столбце column_index меньше или равно порогу t.\n",
    "    # - right: индексы объектов, у которых значение признака\n",
    "    # в столбце column_index больше порога t.\n",
    "    left = np.where(data[:, column_index] <= t)\n",
    "    right = np.where(data[:, column_index] > t)\n",
    "\n",
    "    # Создают два новых массива данных:\n",
    "    # - true_data: объекты, которые удовлетворяют условию\n",
    "    # data[:, column_index] <= t (левая ветвь).\n",
    "    # - false_data: объекты, которые не удовлетворяют условию (правая ветвь).\n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    \n",
    "    # Создают два новых массива меток классов:\n",
    "    # - true_labels: метки классов для объектов из true_data.\n",
    "    # - false_labels: метки классов для объектов из false_data.\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "    \n",
    "    # Возвращает четыре массива:\n",
    "    # - true_data: объекты, удовлетворяющие условию.\n",
    "    # - false_data: объекты, не удовлетворяющие условию.\n",
    "    # - true_labels: метки классов для объектов из true_data.\n",
    "    # - false_labels: метки классов для объектов из false_data.\n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "# Таким образом, функция split разделяет датасет\n",
    "# на два поддерева по заданному признаку и порогу,\n",
    "# возвращая соответствующие данные\n",
    "# и метки классов для каждого поддерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функции predict_object, которая принимает два параметра:\n",
    "# - obj: объект (или пример) для которого нужно сделать предсказание.\n",
    "# - node: текущий узел дерева решений,\n",
    "# с которого начинается или продолжается предсказание.\n",
    "def predict_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    # Проверяют, является ли текущий узел листом (Leaf):\n",
    "    # - isinstance(node, Leaf): проверяет, является ли узел экземпляром класса Leaf.\n",
    "    # - Если узел является листом, извлекается предсказание из узла (node.prediction),\n",
    "    # и это предсказание возвращается как результат функции.\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    # Проверяет, удовлетворяет ли значение признака объекта в текущем узле условию:\n",
    "    # - obj[node.index]: значение признака объекта в текущем узле (индекс признака node.index).\n",
    "    # - <= node.t: проверка, меньше ли или равно ли это значение пороговому значению node.t.\n",
    "    if obj[node.index] <= node.t:\n",
    "\n",
    "        # Вызывается рекурсивная функция predict_object\n",
    "        # для поддерева true_branch (левая ветвь).\n",
    "        return predict_object(obj, node.true_branch)\n",
    "    \n",
    "    # Если значение признака объекта больше порога,\n",
    "    # вызывается рекурсивная функция predict_object\n",
    "    # для поддерева false_branch (правая ветвь).\n",
    "    else:\n",
    "        return predict_object(obj, node.false_branch)\n",
    "    \n",
    "# Таким образом, функция predict_object рекурсивно спускается по дереву решений,\n",
    "# начиная с корневого узла и следуя по ветвям (левая или правая)\n",
    "# в зависимости от значений признаков объекта, пока не достигнет листа.\n",
    "# В листе функция возвращает предсказанное значение,\n",
    "# соответствующее этому листу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функции predict, которая принимает два параметра:\n",
    "# - data: набор данных, для которого нужно сделать предсказания.\n",
    "# Это может быть матрица, где каждая строка представляет собой объект (пример).\n",
    "# - tree: дерево решений, используемое для предсказания.\n",
    "def predict(data, tree):\n",
    "    \n",
    "    # Пустой список preds, в который будут добавляться\n",
    "    # предсказания для каждого объекта из набора данных.\n",
    "    preds = []\n",
    "\n",
    "    for obj in data:\n",
    "\n",
    "        # Для каждого объекта вызывается функция predict_object\n",
    "        # с параметрами obj (текущий объект) и tree (дерево решений).\n",
    "        # Функция predict_object возвращает предсказание для данного объекта,\n",
    "        # которое сохраняется в переменной prediction.\n",
    "        prediction = predict_object(obj, tree)\n",
    "\n",
    "        # Добавляет предсказание prediction в список preds.\n",
    "        preds.append(prediction)\n",
    "\n",
    "    # После завершения цикла функция возвращает список preds,\n",
    "    # который содержит предсказания для всех объектов из набора данных.\n",
    "    return preds\n",
    "\n",
    "# Таким образом, функция predict перебирает все объекты в наборе данных,\n",
    "# используя дерево решений для предсказания класса каждого объекта,\n",
    "# и собирает все предсказания в один список, который затем возвращает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напечатаем ход нашего дерева\n",
    "def print_tree(node, spacing=\"\"):\n",
    "\n",
    "    # Если лист, то выводим его прогноз\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Прогноз:\", node.prediction)\n",
    "        return\n",
    "\n",
    "    # Выведем значение индекса и порога на этом узле\n",
    "    print(spacing + 'Индекс', str(node.index), '<=', str(node.t))\n",
    "\n",
    "    # Рекурсионный вызов функции на положительном поддереве\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Рекурсионный вызов функции на отрицательном поддереве\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Реализуйте дерево для задачи регрессии. Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "data, targets = make_regression(n_features=2, n_informative=2, random_state=5)\n",
    "# Этот код использует функцию make_regression из библиотеки sklearn.datasets\n",
    "# для генерации синтетических данных для задачи регрессии. \n",
    "# Вызывает функцию make_regression и присваивает\n",
    "# результаты двум переменным: data и targets.\n",
    "# Параметры, переданные функции make_regression:\n",
    "# - n_features=2: указывает, что у каждого объекта будет 2 признака.\n",
    "# - n_informative=2: указывает, что оба признака будут информативными,\n",
    "# то есть будут использоваться для вычисления целевой переменной (targets).\n",
    "# - random_state=5: задает начальное значение для генератора случайных чисел,\n",
    "# чтобы результаты были воспроизводимы.\n",
    "# При использовании одного и того же random_state\n",
    "# каждый запуск будет генерировать одинаковые данные.\n",
    "# Теперь о возвращаемых значениях:\n",
    "# - data: массив размером (n_samples, n_features) (по умолчанию n_samples=100),\n",
    "# содержащий сгенерированные признаки. В данном случае, это матрица размером (100, 2).\n",
    "# - targets: массив длиной n_samples, содержащий целевые значения (метки),\n",
    "# соответствующие каждому объекту в data.\n",
    "\n",
    "# Таким образом, функция make_regression создает синтетический набор данных\n",
    "# для задачи регрессии с заданным числом признаков и информативных признаков,\n",
    "# а также фиксирует случайное состояние для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "\n",
    "# Импортирует функцию train_test_split из модуля sklearn.model_selection.\n",
    "# Функция используется для разделения массива данных на обучающую и тестовую выборки.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Вызывает функцию train_test_split и присваивает результат четырем переменным:\n",
    "# - train_data_regr: данные для обучения (признаки).\n",
    "# - test_data_regr: данные для тестирования (признаки).\n",
    "# - train_target_regr: метки (целевые значения) для обучения.\n",
    "# - test_target_regr: метки (целевые значения) для тестирования.\n",
    "train_data_regr, test_data_regr, train_target_regr, test_target_regr = train_test_split(data, \n",
    "                                                                                        targets, \n",
    "                                                                                        test_size=0.3,\n",
    "                                                                                        random_state=1)\n",
    "\n",
    "# Параметры, переданные функции train_test_split:\n",
    "# - data: исходный массив данных (признаки), который нужно разделить.\n",
    "# - targets: исходный массив меток (целевые значения), который нужно разделить.\n",
    "# - test_size=0.3: указывает, что 30% данных будет выделено\n",
    "# на тестовую выборку, а оставшиеся 70% — на обучающую.\n",
    "# - random_state=1: задает начальное значение для генератора случайных чисел,\n",
    "# чтобы разделение данных было воспроизводимым.\n",
    "# При использовании одного и того же random_state\n",
    "# каждый запуск будет генерировать одинаковое разделение данных.\n",
    "\n",
    "# Таким образом, функция train_test_split разбивает исходные данные и метки\n",
    "# на обучающую и тестовую выборки в соответствии с заданным размером тестовой выборки\n",
    "# и фиксированным состоянием генератора случайных чисел для воспроизводимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И класс терминального узла (листа)\n",
    "class Leaf:\n",
    "    \n",
    "    # Метод инициализаinitit__, который вызывается при создании\n",
    "    # нового объекта класса Leaf. Он принимает два параметра:\n",
    "    # - data: набор данных, попавших в данный лист.\n",
    "    # - targets: соответствующие метки (целевые значения) для этих данных.\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "        # Вызывает метод predict() для объекта Leaf\n",
    "        # и сохраняет результат в атрибут prediction.\n",
    "        # Этот метод будет использоваться для предсказания\n",
    "        # целевой переменной для данного листа.\n",
    "        self.prediction = self.predict()\n",
    "    \n",
    "    # Метод predict, который определяет,\n",
    "    # как вычислить предсказание для терминального узла (листа).\n",
    "    def predict(self):\n",
    "\n",
    "        # Возвращает среднее значение меток (целевых переменных) в узле Leaf\n",
    "        # как предсказание для всех объектов, попавших в этот узел.\n",
    "        return self.targets.mean()\n",
    "    \n",
    "# Таким образом, класс Leaf представляет собой терминальный узел дерева решений,\n",
    "# который хранит данные и соответствующие метки для объектов,\n",
    "# попавших в этот узел, и вычисляет предсказание для этих объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяет функцию для вычисления среднеквадратичной ошибки (MSE - Mean Squared Error).\n",
    "def mse(targets):\n",
    "\n",
    "    # Возвращает среднее значение квадрата разности\n",
    "    # между каждым значением целевой переменной и их средним значением,\n",
    "    # что является вычислением среднеквадратичной ошибки (MSE).\n",
    "    return np.mean((targets - targets.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "# Определение функции find_best_split, которая принимает два параметра:\n",
    "# - data: массив признаков (наблюдений), который нужно разделить.\n",
    "# - targets: массив целевых переменных (меток), соответствующих признакам.\n",
    "def find_best_split(data, targets):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_samples_leaf = 5\n",
    "\n",
    "    # Вычислить среднеквадратичную ошибку (MSE) для целевых переменных в корне дерева.\n",
    "    root_mse = mse(targets)\n",
    "\n",
    "    # Инициализируют переменные best_gain, best_t и best_index\n",
    "    # для хранения лучшего прироста, порога и индекса признака для наилучшего разбиения.\n",
    "    best_gain = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    # Количество признаков в наборе данных.\n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    # Цикл перебирает индексы признаков.\n",
    "    for index in range(n_features):\n",
    "\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])\n",
    "        \n",
    "        # Вложенный цикл перебирает все уникальные значения признака.\n",
    "        for t in t_values:\n",
    "\n",
    "            # Вызывает функцию split, чтобы разделить данные и целевые переменные\n",
    "            # на два поддерева на основе текущего признака и порога t.\n",
    "            true_data, false_data, true_targets, false_targets = split(data, targets, index, t)\n",
    "\n",
    "            #  Проверяет, достигается ли минимальное количество объектов в каждом поддереве.\n",
    "            # Если нет, цикл продолжается без учета текущего разбиения.\n",
    "            if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            # Вычисляет прирост качества (gain) для текущего разбиения, используя функцию gain.\n",
    "            current_gain = gain(true_targets, false_targets, root_mse, mse)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_gain > best_gain:\n",
    "                best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "    # Возвращает лучший прирост качества, соответствующий порог t\n",
    "    # и индекс признака index для наилучшего разбиения.\n",
    "    return best_gain, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "# Определение функции build_tree, которая принимает два параметра:\n",
    "# - data: массив признаков (наблюдений), который нужно разделить.\n",
    "# - target: массив целевых переменных (меток), соответствующих признакам.\n",
    "def build_tree(data, target):\n",
    "\n",
    "    # Вызывает функцию find_best_split для нахождения\n",
    "    # наилучшего разбиения на текущем уровне дерева.\n",
    "    # Она возвращает прирост в качестве разбиения (gain),\n",
    "    # порог (t) и индекс признака (index),\n",
    "    # на котором было найдено наилучшее разбиение.\n",
    "    gain, t, index = find_best_split(data, target)\n",
    "\n",
    "    # Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    # Проверяет, достигнут ли базовый случай,\n",
    "    # когда нет прироста в качестве от разбиения.\n",
    "    # Если прирост равен нулю, функция возвращает объект Leaf,\n",
    "    # представляющий терминальный узел дерева.\n",
    "    if gain == 0:\n",
    "        return Leaf(data, target)\n",
    "\n",
    "    # Вызывает функцию split, чтобы разделить данные и целевые переменные\n",
    "    # на два поддерева на основе порога t и индекса признака index.\n",
    "    true_data, false_data, true_target, false_target = split(data, target, index, t)\n",
    "\n",
    "    # Рекурсивно вызывают функцию build_tree для построения двух поддеревьев:\n",
    "    # одного для объектов, удовлетворяющих условию разбиения,\n",
    "    # и другого для объектов, не удовлетворяющих этому условию.\n",
    "    true_branch = build_tree(true_data, true_target)\n",
    "    false_branch = build_tree(false_data, false_target)\n",
    "\n",
    "    # Создает узел (node) с указанием индекса признака (index),\n",
    "    # порога (t) и ссылок на поддеревья (true_branch и false_branch).\n",
    "    node = Node(index, t, true_branch, false_branch)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 0 <= -0.10061434630710828\n",
      "--> True:\n",
      "  Индекс 0 <= -0.8568531547160899\n",
      "  --> True:\n",
      "    Прогноз: -109.75655471490919\n",
      "  --> False:\n",
      "    Индекс 0 <= -0.5732155560138283\n",
      "    --> True:\n",
      "      Прогноз: -54.35634172577482\n",
      "    --> False:\n",
      "      Индекс 1 <= -0.3058530211666308\n",
      "      --> True:\n",
      "        Прогноз: -29.105630694331246\n",
      "      --> False:\n",
      "        Прогноз: -10.772916465924025\n",
      "--> False:\n",
      "  Индекс 0 <= 0.9068894675659355\n",
      "  --> True:\n",
      "    Индекс 1 <= 0.6566194702604272\n",
      "    --> True:\n",
      "      Индекс 1 <= -1.0650326193820066\n",
      "      --> True:\n",
      "        Прогноз: 7.798014762375311\n",
      "      --> False:\n",
      "        Индекс 0 <= 0.41367880834311616\n",
      "        --> True:\n",
      "          Прогноз: 17.019366109004096\n",
      "        --> False:\n",
      "          Прогноз: 35.95087900163848\n",
      "    --> False:\n",
      "      Индекс 0 <= 0.34691932708774675\n",
      "      --> True:\n",
      "        Прогноз: 37.4238776327042\n",
      "      --> False:\n",
      "        Прогноз: 61.9558421220885\n",
      "  --> False:\n",
      "    Индекс 0 <= 1.3348485742415819\n",
      "    --> True:\n",
      "      Прогноз: 77.83232966482356\n",
      "    --> False:\n",
      "      Прогноз: 123.1031262020856\n"
     ]
    }
   ],
   "source": [
    "# Построим дерево по обучающей выборке\n",
    "# Вызывает функцию build_tree, чтобы построить дерево решений\n",
    "# на основе обучающих данных train_data_regr\n",
    "# и соответствующих им меток train_target_regr.\n",
    "# Результат (дерево) сохраняется в переменной my_tree.\n",
    "my_tree = build_tree(train_data_regr, train_target_regr)\n",
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473030504970069\n",
      "0.8558102546515577\n"
     ]
    }
   ],
   "source": [
    "# Импортирует функцию r2_score из модуля sklearn.metrics,\n",
    "# которая используется для вычисления коэффициента детерминации R².\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Вызывает функцию predict для получения предсказанных значений\n",
    "# на обучающей выборке train_data_regr с использованием построенного дерева my_tree.\n",
    "# Результат сохраняется в переменной train_answers.\n",
    "train_answers = predict(train_data_regr, my_tree)\n",
    "\n",
    "# Вычисляет коэффициент детерминации R² между\n",
    "# истинными значениями целевой переменной на обучающей выборке train_target_regr\n",
    "# и предсказанными значениями train_answers с использованием функции r2_score.\n",
    "# Результат сохраняется в переменной train_r2.\n",
    "train_r2 = r2_score(train_target_regr, train_answers)\n",
    "\n",
    "print(train_r2)\n",
    "\n",
    "# Вызывает функцию predict для получения предсказанных значений\n",
    "# на тестовой выборке test_data_regr с использованием построенного дерева my_tree.\n",
    "# Результат сохраняется в переменной answers.\n",
    "answers = predict(test_data_regr, my_tree)\n",
    "\n",
    "# Вычисляет коэффициент детерминации R² между истинными значениями целевой переменной\n",
    "# на тестовой выборке test_target_regr и предсказанными значениями answers\n",
    "# с использованием функции r2_score. Результат сохраняется в переменной test_r2.\n",
    "test_r2 = r2_score(test_target_regr, answers)\n",
    "\n",
    "print(test_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
