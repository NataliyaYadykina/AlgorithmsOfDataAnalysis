{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание <a class=\"anchor\" id=\"hw\"></a><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задача:__ предсказание баллов ЕГЭ ученика в зависимости от кол-ва лет стажа его репетитора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ 1,  1],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2],\n",
    "              [ 1,  5],\n",
    "              [ 1,  3],\n",
    "              [ 1,  0],\n",
    "              [ 1,  5],\n",
    "              [ 1, 10],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Подберите скорость обучения (eta) и количество итераций**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем различные значения eta и количество итераций и выберем те, которые минимизируют среднеквадратичную ошибку (MSE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'eta': 0.05, 'iterations': 500, 'mse': 43.96875}\n"
     ]
    }
   ],
   "source": [
    "# Объявляется функция градиентного спуска с параметрами:\n",
    "# X - матрица признаков, y - вектор целевых значений,\n",
    "# eta - скорость обучения (learning rate),\n",
    "# iterations - количество итераций (эпох обучения).\n",
    "def gradient_descent(X, y, eta, iterations):\n",
    "    # Определяется количество обучающих примеров в матрице X.\n",
    "    n = X.shape[0]\n",
    "    # Инициализируется вектор весов w нулями.\n",
    "    # Количество элементов вектора соответствует количеству признаков.\n",
    "    w = np.zeros(X.shape[1])\n",
    "\n",
    "    # Начинается цикл по количеству итераций.\n",
    "    for i in range(iterations):\n",
    "        # Вычисляются предсказанные значения целевой переменной y\n",
    "        # на основе текущих весов w и матрицы признаков X\n",
    "        # с помощью скалярного произведения.\n",
    "        y_pred = np.dot(X, w)\n",
    "        # Вычисляется среднеквадратичная ошибка между\n",
    "        # предсказанными значениями y_pred и реальными значениями y с помощью функции calc_mse.\n",
    "        err = calc_mse(y, y_pred)\n",
    "        # Вычисляется градиент функции потерь (в данном случае среднеквадратичной ошибки)\n",
    "        # с учетом предсказанных значений и реальных значений целевой переменной.\n",
    "        dQ = 2/n * X.T @ (y_pred - y)\n",
    "        # Обновляются веса w с помощью градиентного спуска,\n",
    "        # умножая градиент на скорость обучения eta.\n",
    "        w -= eta * dQ\n",
    "    # Возвращается обновленный вектор весов w.\n",
    "    return w\n",
    "\n",
    "# Задаются значения скорости обучения, которые нужно проверить.\n",
    "etas = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "# Задаются значения количества итераций, которые нужно проверить.\n",
    "iterations = [100, 500, 1000, 2000]\n",
    "\n",
    "# Инициализируется словарь для хранения лучших параметров:\n",
    "# скорости обучения, количества итераций и значения среднеквадратичной ошибки.\n",
    "# Изначально ошибка устанавливается на бесконечность,\n",
    "# чтобы гарантировать ее обновление при нахождении более низкого значения.\n",
    "best_params = {'eta': None, 'iterations': None, 'mse': float('inf')}\n",
    "\n",
    "# Начинается цикл по всем значениям скорости обучения.\n",
    "for eta in etas:\n",
    "    # Внутренний цикл по всем значениям количества итераций.\n",
    "    for iteration in iterations:\n",
    "        # Применяется функция градиентного спуска для определенной\n",
    "        # комбинации скорости обучения и количества итераций.\n",
    "        w = gradient_descent(X, y, eta, iteration)\n",
    "        # Вычисляются предсказанные значения целевой переменной y\n",
    "        # на основе текущих весов w и матрицы признаков X.\n",
    "        y_pred = np.dot(X, w)\n",
    "        # Вычисляется среднеквадратичная ошибка между\n",
    "        # предсказанными значениями y_pred и реальными значениями y.\n",
    "        mse = calc_mse(y, y_pred)\n",
    "        # Если текущее значение среднеквадратичной ошибки меньше,\n",
    "        # чем лучшее значение, обновляем лучшие параметры.\n",
    "        if mse < best_params['mse']:\n",
    "            best_params['eta'] = eta\n",
    "            best_params['iterations'] = iteration\n",
    "            best_params['mse'] = mse\n",
    "\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот код позволит определить оптимальные значения скорости обучения и количества итераций, минимизирующие среднеквадратичную ошибку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2*. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n",
      "Iteration #10: W_new = [ 7.0011236 10.6169007], MSE = 738.65\n",
      "Iteration #20: W_new = [10.3486292  10.10603105], MSE = 622.03\n",
      "Iteration #30: W_new = [13.38789582  9.55618391], MSE = 525.24\n",
      "Iteration #40: W_new = [16.16088505  9.05336203], MSE = 444.66\n",
      "Iteration #50: W_new = [18.69110735  8.59454545], MSE = 377.58\n",
      "Iteration #60: W_new = [20.99981865  8.17589626], MSE = 321.72\n",
      "Iteration #70: W_new = [23.10641138  7.79389815], MSE = 275.22\n",
      "Iteration #80: W_new = [25.02858024  7.44534246], MSE = 236.5\n",
      "Iteration #90: W_new = [26.78247081  7.12730145], MSE = 204.27\n"
     ]
    }
   ],
   "source": [
    "# Ошибка в данном коде связана с неправильным обновлением весов.\n",
    "# В градиентном спуске веса должны обновляться сразу для всех признаков,\n",
    "# используя градиент функции потерь по всем обучающим примерам.\n",
    "# В текущей реализации градиент вычисляется неверно,\n",
    "# так как он должен быть по всем объектам обучающей выборки,\n",
    "# а не только по предсказанным значениям на текущих весах. \n",
    "\n",
    "n = X.shape[0]\n",
    "\n",
    "eta = 1e-2 \n",
    "n_iter = 100\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    # ОШИБКА\n",
    "    # W -= eta * (1/n * 2 * np.dot(X, y_pred - y))\n",
    "    # ОШИБКА\n",
    "    # ИЗМЕНЕНИЯ\n",
    "    W -= eta * (1/n * 2 * np.dot(X.T, y_pred - y))\n",
    "    # ИЗМЕНЕНИЯ\n",
    "    #\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3*. Вместо того, чтобы задавать количество итераций, задайте другое условие останова алгоритма - когда веса перестают изменяться меньше определенного порога $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n",
      "Iteration #100: W_new = [28.38281518  6.83710367], MSE = 177.43\n",
      "Iteration #200: W_new = [38.38986469  5.02247953], MSE = 65.33\n",
      "Iteration #300: W_new = [42.39314129  4.29654705], MSE = 47.39\n",
      "Iteration #400: W_new = [43.99463466  4.00614091], MSE = 44.52\n",
      "Iteration #500: W_new = [44.63530512  3.8899652 ], MSE = 44.06\n",
      "Iteration #600: W_new = [44.89160255  3.84348962], MSE = 43.98\n",
      "Iteration #700: W_new = [44.99413322  3.82489726], MSE = 43.97\n",
      "Iteration #800: W_new = [45.03515017  3.81745947], MSE = 43.97\n",
      "Iteration #900: W_new = [45.05155882  3.81448401], MSE = 43.97\n",
      "Iteration #1000: W_new = [45.05812303  3.8132937 ], MSE = 43.97\n",
      "Iteration #1100: W_new = [45.06074901  3.81281751], MSE = 43.97\n",
      "Iteration #1200: W_new = [45.06179952  3.81262702], MSE = 43.97\n",
      "Iteration #1300: W_new = [45.06221978  3.81255081], MSE = 43.97\n",
      "Iteration #1400: W_new = [45.0623879   3.81252033], MSE = 43.97\n",
      "Algorithm converged after 1407 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Задается скорость обучения (learning rate).\n",
    "# Она определяет размер шага, с которым алгоритм градиентного спуска обновляет веса.\n",
    "eta = 1e-2 \n",
    "# Задается порог изменения весов.\n",
    "# Это значение определяет минимальное изменение весов,\n",
    "# при котором алгоритм будет продолжать итерации.\n",
    "epsilon = 1e-6\n",
    "# Задается максимальное количество итераций.\n",
    "# Это предотвращает зацикливание алгоритма,\n",
    "# если он не сможет сойтись к оптимальным весам.\n",
    "max_iter = 10000\n",
    "\n",
    "# Инициализируются начальные значения весов.\n",
    "W = np.array([1, 0.5])\n",
    "# Определяется количество обучающих примеров в матрице X.\n",
    "n = X.shape[0]\n",
    "\n",
    "# Выводится информация о количестве обучающих примеров,\n",
    "# скорости обучения и начальных значениях весов.\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "# Начинается цикл по количеству максимально допустимых итераций.\n",
    "for i in range(max_iter):\n",
    "    # Вычисляются предсказанные значения целевой переменной y\n",
    "    # на основе текущих весов W и матрицы признаков X.\n",
    "    y_pred = np.dot(X, W)\n",
    "    # Вычисляется среднеквадратичная ошибка\n",
    "    # между предсказанными значениями y_pred и реальными значениями y.\n",
    "    err = calc_mse(y, y_pred)\n",
    "    # Сохраняются предыдущие значения весов для последующего сравнения.\n",
    "    W_prev = np.copy(W)\n",
    "    # Обновляются веса W с помощью градиентного спуска,\n",
    "    # учитывая градиент функции потерь.\n",
    "    W -= eta * (1/n * 2 * np.dot(X.T, y_pred - y))\n",
    "    # Проверяется условие останова:\n",
    "    # если изменение весов меньше порога, алгоритм считается сойденным.\n",
    "    if np.linalg.norm(W - W_prev) < epsilon:\n",
    "        # Если алгоритм сходится, выводится информация о количестве выполненных итераций.\n",
    "        print(f'Algorithm converged after {i+1} iterations.')\n",
    "        break\n",
    "    # Каждые 100 итераций выводится информация\n",
    "    # о текущих значениях весов и среднеквадратичной ошибке.\n",
    "    if i % 100 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err, 2)}')\n",
    "\n",
    "# Если максимальное количество итераций достигнуто,\n",
    "# выводится сообщение о достижении предела\n",
    "# и рекомендация изменить скорость обучения или порог epsilon.\n",
    "if i == max_iter - 1:\n",
    "    print('Maximum number of iterations reached. Consider changing the learning rate or epsilon.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
